<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://brunompacheco.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://brunompacheco.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-10-02T21:39:08+00:00</updated><id>https://brunompacheco.github.io/feed.xml</id><title type="html">blank</title><subtitle>Bruno&apos;s webpage and blog.
</subtitle><entry><title type="html">Reflections on BRACIS 2023: AI Regulation, guarantees and the case for Brazil</title><link href="https://brunompacheco.github.io/blog/2023/bracis-insights/" rel="alternate" type="text/html" title="Reflections on BRACIS 2023: AI Regulation, guarantees and the case for Brazil" /><published>2023-10-01T00:00:00+00:00</published><updated>2023-10-01T00:00:00+00:00</updated><id>https://brunompacheco.github.io/blog/2023/bracis-insights</id><content type="html" xml:base="https://brunompacheco.github.io/blog/2023/bracis-insights/"><![CDATA[<p>I have just returned home from a week at Belo Horizonte (MG), attending the <a href="https://www.bracis.dcc.ufmg.br/">12th Brazilian Conference on Intelligent Systems - BRACIS</a>.
Besides presenting<d-footnote>Slides available at <a href="https://github.com/gama-ufsc/brain-age/">github.com/gama-ufsc/brain-age</a></d-footnote> our paper on deep-learning-based brain age estimation and the effects of pre-training such models <d-cite key="pacheco2023does"></d-cite>, I was able to attend great presentations and have wonderful discussions with the researchers present at the event.
This post is a tentative summary of my major takeaways from the event, some insights I had while there, and a few highlights of the presentations.
As this blog is my personal space, I’ll take the liberty of being provocative<d-footnote>Feel free to reach me out if you want to weigh in :)</d-footnote>.</p>

<h2 id="navigating-ethic-and-regulatory-challenges">Navigating ethic and regulatory challenges</h2>

<p>One recurring theme that resonated throughout BRACIS 2023 was the baffling task of mitigating the risks associated with machine learning applications.
The discussions encompassed a wide spectrum, from enhancing the reliability of AI systems to the complexities of crafting and ratifying regulations for these technologies, all while pondering the ethical implications of such advancements.</p>

<p>One illuminating presentation came from prof. Edgar Lyra of PUC-RIO, who presented three complimentary perspectives on ensuring the ethical use of AI, which I found very useful to break down the analysis.
One approach, as I understood, involves restricting the application of machine learning technologies (e.g., through legislation), as in the <a href="https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence">EU AI Act</a>.
Another avenue is to develop techniques and bureaucratic processes that guarantee ethical applications, perhaps by establishing councils to certificate professionals, akin to those in the civil construction industry.
An example, <a href="https://www25.senado.leg.br/web/atividade/materias/-/materia/157233">PL 2338/2023</a> stipulates the creation of several governance measures from the parts involved, making it somewhat possible to audit the applications.</p>

<p>Then, there is the education perspective, ensuring that all stakeholders impacted by ML applications are well-versed in the associated risks and limitations.
A great example of the relevance of widespread education came in the presentation of “Regulation and Ethics of Facial Recognition Systems: an analysis of cases in the Court of Appeal in the State of São Paulo”, during the best papers session.
The authors observed a lack of well-grounded arguments with respect to the machine learning techniques in the judges’ decisions, leading to unfair settlements, which highlights the urgency of the educational aspect.</p>

<p>Regarding regulatory efforts, I’m still grappling with the idea of crafting pertinent laws in the face of the rapidly evolving landscape of AI research.
An illustrative example is the delay of the EU AI Act after the launch of ChatGPT.
However, I believe the lawmakers’ discussions on possible regulations for AI are, currently, the major drivers of wide-spread education on the subject, along with (often misleading) news.
Thus, at least some benefit is being drawn out of it.</p>

<h2 id="ai-safety-guarantees-and-structured-data">AI safety, guarantees, and structured data</h2>

<p>Discussions on machine learning safety typically revolved around terms like explainability, trust, interpretability, and model transparency.
Personally, I find it difficult to see how any technique that provides an “intuition” on model behavior serves more purpose than just calming down the uneducated user<d-footnote>This is true in the context of the deployed application. I value (and, actually, frequently use) explanation techniques to debug models and guide development and research.</d-footnote>.
In fact, for deep learning models, I have a huge difficulty to trust anything beyond generalization performance estimates (which are often hard to communicate effectively) and theoretical guarantees (which can be very hard to provide for high-performance models).
As discussed by prof. Baeza-Yates, in the absence of theoretical guarantees, i.e., if we know that a model will eventually fail, one might question the ethics of deploying such a deep-learning-based application.</p>

<p>However, one intriguing insight was mentioned by prof. Paulo Quaresma and was further materialized during the GNN paper sessions.
These conversations underscored the value of encoding symbolic knowledge into the data.
More specifically, using such knowledge to augment the model’s output is a viable way to provide solid guarantees.
A clear example can be seen in tasks like node classification, where the model’s output aligns with the structure of the input graph—a domain I find compelling due to my current research interest in GNNs.
For me, this is a reminder that, amidst the quest for safety in AI, leveraging structured data can be a promising avenue for crafting truly reliable applications.</p>

<h2 id="leveraging-research-and-development-in-brazil">Leveraging research and development in Brazil</h2>

<p>Beyond the challenges of AI, BRACIS 2023 also hosted very insightful discussions on strategies for Brazil to harness the potential of AI research and development.
The discussions involved representatives from various sectors, including government, academia, and the private sector.
This collaboration was driven by several factors, of which I highlight a few in the following.</p>

<h3 id="brain-drain">Brain drain</h3>

<p>Our research institutions face a significant “brain drain”.
The talent retention difficulty comes mainly from an increasing demand for computer scientists in the private sector.
Not only our companies are opening more positions for the researchers, but now, due to the remote work opportunities, the academia has to compete with foreign companies.
Therefore, the competition for human resources ends up happening in foreign currency, which is particularly hard on academic institutions with government funding.</p>

<h3 id="government-impact">Government impact</h3>

<p>Recent AI-based technologies (e.g., facial recognition, employment decision-making, chatbots) have had a profound impact on various aspects on society and governance.
I have mentioned above how lawmakers and judges are struggling to handle these new technologies, but the challenges spread through all three powers of the government.
The executive has to position the country with respect to the international partnerships to avoid misuse of our resources (human and data), and nationally to stimulate the use of these technologies to promote sustainable development.</p>

<h3 id="innovation-opportunities">Innovation opportunities</h3>

<p>At the same time, as the AI industry is still in its early stages, we have the opportunity to become active players in the global AI landscape, rather than passive consumers.
Brazil’s public and private sectors are united in this perspective.
However, neither have clear paths for promoting the national role in the global community.</p>

<p><br />
<br /></p>

<p>One approach to leverage our AI research and development that garnered significant attention was the provision of hardware resources for researchers.
While this idea initially holds promise, especially in terms of enhancing data privacy and facilitating research on large deep learning models, I have a concern that Brazil may have an unbridgeable gap behind global leaders.
Given that our country does not have a significant presence in the semiconductor industry, I believe the costs of achieving and maintaining state-of-the-art computing performance may be prohibitively high.
An alternative could be to leverage our existing multilateral and bi-lateral partnerships, which the representatives of the <a href="https://www.gov.br/mcti/pt-br">MCTI</a> ensured are abundant, and establish secure connections to privately access dedicated computational resources abroad.
This way, we could leapfrog some of the infrastructure limitations and stay competitive on the global stage.</p>

<p>Another insight emerged in my mind during the “C&amp;T&amp;I on AI in Brazil” panel – perhaps our focus should not be on competing in the hottest AI topics but rather on finding our place within the global AI value chain.
I find it unlikely that the next breakthroughs in LLMs will come from Brazil, no matter how much the government may invest in hardware, because I don’t see unique strengths that could make us leapfrog the current players.
I believe we should find our “Amazons” of AI, that is, our assets that could become an advantage in the competition.
For example, as highlighted by Luiz Reali from OBIA, we are at the forefront of digitizing several state-wide services (see <a href="https://www.gov.br/pt-br">gov.br</a>, <a href="https://www.bcb.gov.br/estabilidadefinanceira/pix">pix</a>, and <a href="https://jus.com.br/artigos/4795/a-virtualizacao-dos-processos-judiciais-e-proc-e-a-dispensabilidade-de-autenticacao-documental-por-tabeliao">e-proc</a>).
This grants us access to vast amounts of data and a natural interface for developing AI applications in the governmental sector.
By capitalizing on these strengths, Brazil could pioneer AI-driven governmental applications, carving out a distinct and impactful role in the AI revolution.</p>

<h2 id="concluding-remarks">Concluding remarks</h2>

<p>I had a wonderful time at BRACIS and not everything fits in the previous sections.
Beyond the ones already mentioned above, some great keynotes that I would like to highlight: prof. Banzhaf on evolutionary machine learning, with some very interesting applications to reinforcement learning; prof. Benevenuto on data science techniques to audit social networks and messaging apps; prof. Bazzan on graph analysis and applications; and prof. Hutter and the meta-learning paradigm for tabular data.</p>

<p>Furthermore, many great papers were presented throughout the week.
My favorite were: <em>Embracing data irregularities in multivariate time series with Recurrent and Graph Neural Networks</em>, by Barros et al.; <em>A combinatorial optimization model and polynomial time heuristic for a problem of finding specific structural patterns in networks</em>, by Lima and Sampaio; <em>The Multi-Attribute Fairer Cover Problem</em>, by Dantas et al.; and <em>Allocating Dynamic and Finite Resources to a Set of Known Tasks</em>, by Silva et al.</p>

<p>I’m returning home more motivated and eager to collaborate, after getting to know other researchers, their contributions, visions, struggles, and “a-has”.
Also, by feeding from the experts and more experienced researchers, I’m more confident and with expanded horizons.
It was a great event.</p>]]></content><author><name>Bruno M. Pacheco</name></author><category term="opinion" /><category term="ai" /><category term="deep-learning" /><category term="gnns" /><summary type="html"><![CDATA[An opinion post on key insights and takeaways from the event.]]></summary></entry><entry><title type="html">ML4CO - Part 1: A brief overview of machine learning for combinatorial optimization</title><link href="https://brunompacheco.github.io/blog/2023/literature-review-ml4co-1/" rel="alternate" type="text/html" title="ML4CO - Part 1: A brief overview of machine learning for combinatorial optimization" /><published>2023-06-14T00:00:00+00:00</published><updated>2023-06-14T00:00:00+00:00</updated><id>https://brunompacheco.github.io/blog/2023/literature-review-ml4co-1</id><content type="html" xml:base="https://brunompacheco.github.io/blog/2023/literature-review-ml4co-1/"><![CDATA[<!-- TODO: find a better way to highlight this first section -->
<p><em>This text is a direct result from the literature review I performed for my Master’s.
The main goal of this first part is to provide context and background for the following review on end-to-end learning-based heuristics for MILP.
This is largely based on the work by Bengio et al.<d-cite key="bengio_machine_2021"></d-cite>, so I recommend it to the reader that wants to find more detailed information and more references.</em></p>

<!-- ###  ‎ -->
<p><br /></p>

<p>Let us suppose that a delivery company must plan the route for a carrier given a set of packages.
The route must take the carrier through the recipients of every package and back to the company headquarters.
As there are finitely many packages, there are finitely many possible routes.
To find the optimal route, you can write a computer program that evaluates all possible routes and returns the one with the smallest cost.
It is easy to see that this program will always (eventually) finish and will return the optimal solution.
However, as the number of solutions (routes) grows exponentially with the size of the problem (number of recipients/packages), for a large-enough number of deliveries, committing to a random route will probably be faster than waiting for the program to finish.
This example is a classic occurrence of the Traveling Salesperson Problem (TSP), a widely studied combinatorial optimization (CO) problem.</p>

<p>CO problems are hard.
In fact, CO is often used to refer to NP-hard integer optimization problems.
But despite being NP-hard, many CO problems are solved within reasonable time even for millions of variables (and constraints).
This is usually due to experts being able to exploit structures of the problem, creating efficient heuristics.</p>

<p>In the delivery company example, suppose that you are quite familiar with the location of the deliveries.
You modify the computer program, such that instead of iterating over all possible solutions, you remove routes that pass through residential, low-speed areas and prioritize routes that use high-speed roads.
Your new computer program will not iterate over all possible routes, so it may not find the optimal solution, but it will probably give you a very good route much quicker than the previous one.
Furthermore, instead of writing a computer program, you can let an experienced carrier guess a route based on their previous deliveries.
The guess probably won’t be the best route, but it may be good enough.</p>

<p>Sadly, the expert knowledge to develop heuristics for CO problems takes a lot of effort to develop and may result in heuristics that are not cheap to compute or easy to implement.
Machine learning (ML) techniques, on the other hand, seem like the perfect fit for such heuristics, as they do not require an expert and are really fast to compute.
On top of that, deep learning has shown great results applied to high-dimensional structured data such as image, proteins, and text, which makes us think that it could provide great results as well when applied to CO problem instances.</p>

<p>For example, computing which routes pass by low-speed zones and which do not may be as expensive as finding a good route.
At the same time, historical data on past routes along with the speed at each section can be used to train a classifier that determines whether a new route is slow or not.
Furthermore, instead of embedding the graph-like traffic data into a low-dimensional, tabular format for machine learning models, one can use a graph neural network as the classifier.</p>

<h2 id="algorithm-selection">Algorithm selection</h2>

<p>A CO problem is a problem of minimizing an <em>objective function</em> given a finite set of <em>feasible solutions</em>.
Given an algorithm for solving CO problems, its quality is usually determined from its computational complexity and experimental results on benchmark instances.
However, an algorithm that works well on some classes of CO problems may not work well on others.
Thus, practitioners end up having to experiment between the alternatives and, if none fulfills the requirements, having to adjust configurations, exploring the problem’s structure, manually building heuristics, etc.</p>

<p>To better grasp the challenge of selecting an algorithm for a realistic application, let us take the delivery company example of the introduction.
We are going to suppose that the desired computer program must work only for problems on a given city and that the origin (company headquarters) is always the same.
The goal of the company is to find a software that can find a good route within a time limit.
Instead of picking a solver based on benchmarks, you test a few different solvers based on historical data (past orders).
As your instances are too large, none of the algorithms can find a good solution on time given their default setting, so you explore different configurations, tweaking the parameters in the hope of improving their performance.
Furthermore, you notice that the recipients are often grouped in certain regions, so you design an algorithm that first groups nearby recipients in a single vertex, solves this simplified problem, and then finds a route within each group of recipients given the outcome of the simplified problem.</p>

<p>We can provide a mathematical formulation for the problem of finding a good algorithm for the problem of interest.
Let \(\mathcal{I}\) be the set of all instances of interest and \(P\) be a probability distribution over \(\mathcal{I}\).
Let \(\mathcal{A}\) be the set of all algorithms that can solve instances of the problem of interest and \(m : \mathcal{I}\times \mathcal{A}\to \mathbb{R}\) be a performance metric
For convenience, we will assume that, for any \(a_1,a_2 \in \mathcal{A}\) and \(I \in  \mathcal{I}\), then \(m\left( I,a_1 \right) &gt; m\left( I,a_2 \right)\) implies that \(a_1\) outperforms \(a_2\) in instance \(I\).
The problem of finding the best algorithm can be described as</p>

\[\max_{a\in \mathcal{A}} \, \mathbb{E}_{I\sim P } m(I,a)
.\]

<p>As this is usually impossible to compute, one can use the approximation based on a dataset \(\mathcal{D}\) of instances independently drawn from \(P\).
The problem, then, becomes</p>

\[\max_{a\in \mathcal{A}} \, \frac{1}{|\mathcal{D}|} \sum_{I\in \mathcal{D}} m(I,a)
.\]

<h2 id="learning-based-heuristics">Learning-based heuristics</h2>

<p>When we consider CO algorithms enhanced with machine learning models, the comparison is often over an uncountable set of algorithms.
For example, let \(\Theta\) be the parameter space of the ML models, and \(\mathcal{A}=\left\{ a_\theta : \theta\in \Theta \right\}\), i.e., the algorithms are defined by the ML model’s parameters.
The problem of selecting the best algorithm can be written</p>

\[\max_{\theta\in \Theta} \, \frac{1}{|\mathcal{D}|} \sum_{I\in \mathcal{D}} m(I,a_\theta)
.\]

<p>In other words, rather than searching for the best algorithm, one searches for the best vector of parameters.</p>

<p>With respect to how ML models can be used in algorithms for CO, Bengio et al.<d-cite key="bengio_machine_2021"></d-cite> proposed three categories of learning-based heuristics.
Even though the categorization is not exhaustive (as will be seen later on), it is useful to show the possibilities that exist for applying ML models.</p>

<p>At the “deepest” level, an ML model can be trained to take decisions within CO solvers, replacing costly computations or in the place of already existing heuristics within the solver.
An example of this approach can be seen in Nair et al.<d-cite key="nair_solving_2021"></d-cite>, where the authors trained a deep learning model to select between variables for branching, within a branch-and-bound algorithm.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bengio_aoa-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bengio_aoa-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bengio_aoa-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/bengio_aoa.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Diagram of a ML model being used to take decisions within a CO solver (<em>OR</em> block). Image from Bengio et al.<d-cite key="bengio_machine_2021"></d-cite>.
</div>

<p>The second category comprises heuristics with ML models being called to take decisions prior to the execution of the CO solvers.
In this approach, the ML model’s output helps to define the information provided to the CO solver.
In Kruber et al.<d-cite key="kruber_learning_2017"></d-cite>, the authors trained a model to decide whether to apply a Dantzig-Wolfe decomposition to reformulate an instance or not, based on the predicted running time reduction of the solver.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bengio_l2c-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bengio_l2c-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bengio_l2c-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/bengio_l2c.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Diagram of a ML model being used to enhance the information provided to a CO solver (<em>OR</em> block). Image from Bengio et al.<d-cite key="bengio_machine_2021"></d-cite>.
</div>

<p>Finally, ML models can be trained to predict a solution based on the information of an instance, which will be referred to as an <em>end-to-end</em> approach.
An example is the work by Vinyals et al.<d-cite key="vinyals_pointer_2015"></d-cite>, in which the authors propose a novel deep learning model capable of providing feasible solutions to the TSP.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bengio_e2e-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bengio_e2e-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bengio_e2e-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/bengio_e2e.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Diagram of a ML model being used as a heuristic by itself, i.e., without calling an optimization algorithm. This is the end-to-end approach. Image from Bengio et al.<d-cite key="bengio_machine_2021"></d-cite>.
</div>

<p>Note that end-to-end models, beside being trained to predict a solution, can be used in different settings.
For example, the model’s output (a candidate solution) can be used to define a region for proximity search, as done by Han et al.<d-cite key="han_gnn-guided_2023"></d-cite>.</p>

<h2 id="training-ml-models">Training ML models</h2>

<h3 id="supervised-learning">Supervised learning</h3>

<p>For any given structure of CO learning-based heuristic, training through supervision requires us to provide data on the inputs and expected outputs for the model.
We assume that the training data was generated by an “expert”, which the model will learn to imitate.
Therefore, if we provide the model with the optimal solutions as targets, the model will learn to solve the optimization problems.</p>

<p>Supervised learning is possible whenever we have either observations on the expert (e.g., historical performance of a human operator), or access to a data generation process (e.g., artificial instances of the problem and targets given by a solver).
However, supervised learning is mostly adequate to problems in which the expert is not suitable for the application, e.g., because it is too expensive to compute, once the ML model’s performance will, at best, be <em>on par</em> with the expert’s performance.</p>

<p>In Gasse et al.<d-cite key="gasse_exact_2019"></d-cite>, the authors take as an expert the strong branching rule, which is known to provide good results in branch-and-bound, but is expensive to compute.
The data is generated beforehand and fed to the training algorithm as input-output pairs, which guides the ML model towards imitating the rule.</p>

<h3 id="reinforcement-learning">Reinforcement learning</h3>

<p>Instead of teaching the model the desired behavior (targets), we can let the model learn by trial-and-error.
More precisely, the model can be seen as an <em>agent</em> that modifies the <em>state</em> of an <em>environment</em> (e.g., current node of a branch-and-bound tree) through <em>actions</em> (e.g., variable selection for branching).
For the model to learn, we need to provide a function that <em>rewards</em> the model if the desired states are achieved or the right actions are performed.</p>

<p>To use reinforcement learning, therefore, we do not need the expected outputs of the model.
If the reward signal matches the optimization goal, the model will learn to solve the optimization problems without ever being told what the solutions are.
Note that this allows for the model to outperform any known method.
However, as there are usually many possible actions (dimensionality of the model’s output) and states, the learning problem quickly becomes intractable.</p>

<p>In contrast to the example from the previous section (Supervised learning), in Etheve et al.<d-cite key="etheve_reinforcement_2020"></d-cite>, the authors propose to learn branching from scratch.
They adapt reinforcement learning techniques (Q-learning) and propose an approach specific for the branch-and-bound setting.
Through the proposed framework, the model learns to minimize the size of the branch-and-bound tree (global metric).
Notably, all evaluated frameworks require thousands of iterations to achieve competitive performance, in which each iteration requires the optimization of hundreds of CO problems, i.e., the computational cost for training is high even for problems of modest size.</p>

<h2 id="challenges">Challenges</h2>

<p>Regardless of the heuristic configuration or the training approach, developing machine learning models for CO problems faces challenges.</p>

<h3 id="data-generation">Data generation</h3>

<p>The performance of learning algorithms depends heavily on the data available, both in quantity and in quality.
<!-- To have a reliable estimation of the generalization error, it is essential that the test set is drawn from a realistic distribution.
The same is true for the training set, but with respect to reducing the generalization error. -->
The most straight-forward way to build the datasets is to sample from historical data.
In the delivery company example of the introduction, this is equivalent to acquiring the problems and the routes of past deliveries.
Although a valid approach for collecting realistic instances of CO problems, sampling from historical data limits the performance (on training and evaluation) to that of the previous “expert”.
Furthermore, applications that have large-enough historical data are usually those for which a fast-enough solution already exists, limiting the gains to computational speed-ups.</p>

<p>A more general scenario is to have to generate problem instances for training and testing.
<!-- This scenario usually inccurs in high development costs, as finding good solutions (even when just for the test set, in the case of RL) is computationally costly for problems of practical interest.
Furthermore, even determining whether a problem instance is feasible or not is generally itself an NP-hard problem.
On top of that, we known that (assuming NP $$\neq$$ co-NP) polynomial-time instance generation methods for CO problems actually sample from easier sub-problems<d-cite key="yehuda_2020"></d-cite>. -->
Some interesting references on generating instances of optimization problems can be seen in the works by Smith-Miles et al.<d-cite key="smith-miles_generating_2015"></d-cite> and Malitsky et al.<d-cite key="malitsky_structure-preserving_2016"></d-cite>.</p>

<!-- TODO -->
<!-- ### Dimensionality

CO problems have high dimensionality and are highly structured.
=> the higher the number of dimensions, exponentially more data is necessary for learning
Traditional ML models are not built to deal with the structures within CO problems, e.g., TSP (invariant to graph definition). -->

<h3 id="guarantees">Guarantees</h3>

<p>Opting for a heuristic solution (usually) implies in abdicating from optimality guarantees.
However, with machine learning, even feasibilty is often off the table, as constraining the model’s output is usually impossible.</p>

<p>This is not impactful on applications in which the model is used to select between optimality/feasibility-preserving choices.
For example, Liberto et al.<d-cite key="liberto_dash_2016"></d-cite> train a model to select between branching strategies.
However, if the model must provide a candidate solution or a valid constriant, it is often the case that the best we can do is to teach the model to respect feasibility constraints, e.g., through lagrangian regularization.</p>

<h3 id="problem-size">Problem size</h3>

<p>Problems of interest for heuristics are often very large.
As discussed before, larger problems imply in higher costs for generating feasible instances and finding good solutions.
However, large problems also imply in higher dimensionality, which increases (exponentially) the expected training set size for achieving satisfactory performance, and also the trianing cost.
This can be alleviated by exploring symmetries of the problem or working in the embedding of the instance.
For example, many works have exploited the efficiency of graph neural networks by embedding the instances as graphs.</p>

<!-- Maybe add a conclusion discussing the forthcomings? I believe I could, inspired by Smith, 1999, describe why ML+CO is attracting plenty of attention now (in comparison to the 90s), and use this as a hook to Part 2, because of structured models/GNNs. -->

<!-- ###  ‎ -->
<p><br /></p>

<p><em>That was it for this first part.
In part 2, I will dive deeper into end-to-end models trained through supervision, and end-to-end heuristics using these models.</em></p>]]></content><author><name>Bruno M. Pacheco</name></author><category term="literature-review" /><category term="ml4co" /><category term="milp" /><category term="msc-thesis" /><category term="deep-learning" /><summary type="html"><![CDATA[The big picture on machine learning applications as heuristics for combinatorial optimization.]]></summary></entry></feed>